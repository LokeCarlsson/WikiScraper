<!DOCTYPE html>/n<html class="client-nojs" lang="en" dir="ltr">/n<head>/n<meta charset="UTF-8"/>/n<title>Lexical analysis - Wikipedia</title>/n<script>document.documentElement.className = document.documentElement.className.replace( /(^|\s)client-nojs(\s|$)/, "$1client-js$2" );</script>/n<script>(window.RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgCanonicalNamespace":"","wgCanonicalSpecialPageName":false,"wgNamespaceNumber":0,"wgPageName":"Lexical_analysis","wgTitle":"Lexical analysis","wgCurRevisionId":807206513,"wgRevisionId":807206513,"wgArticleId":81251,"wgIsArticle":true,"wgIsRedirect":false,"wgAction":"view","wgUserName":null,"wgUserGroups":["*"],"wgCategories":["All accuracy disputes","Articles with disputed statements from May 2010","All articles with unsourced statements","Articles with unsourced statements from April 2008","Compiler construction","Programming language implementation","Parsing"],"wgBreakFrames":false,"wgPageContentLanguage":"en","wgPageContentModel":"wikitext","wgSeparatorTransformTable":["",""],"wgDigitTransformTable":["",""],"wgDefaultDateFormat":"dmy","wgMonthNames":["","January","February","March","April","May","June","July","August","September","October","November","December"],"wgMonthNamesShort":["","Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec"],"wgRelevantPageName":"Lexical_analysis","wgRelevantArticleId":81251,"wgRequestId":"WfTyzwpAAEYAAEKyHqAAAAAE","wgIsProbablyEditable":true,"wgRelevantPageIsProbablyEditable":true,"wgRestrictionEdit":[],"wgRestrictionMove":[],"wgFlaggedRevsParams":{"tags":{}},"wgStableRevisionId":null,"wgWikiEditorEnabledModules":{"toolbar":true,"preview":false,"publish":false},"wgBetaFeaturesFeatures":[],"wgMediaViewerOnClick":true,"wgMediaViewerEnabledByDefault":false,"wgPopupsShouldSendModuleToUser":true,"wgPopupsConflictsWithNavPopupGadget":false,"wgVisualEditor":{"pageLanguageCode":"en","pageLanguageDir":"ltr","pageVariantFallbacks":"en","usePageImages":true,"usePageDescriptions":true},"wgPreferredVariant":"en","wgMFExpandAllSectionsUserOption":false,"wgMFDisplayWikibaseDescriptions":{"search":true,"nearby":true,"watchlist":true,"tagline":false},"wgRelatedArticles":null,"wgRelatedArticlesUseCirrusSearch":true,"wgRelatedArticlesOnlyUseCirrusSearch":false,"wgULSCurrentAutonym":"English","wgNoticeProject":"wikipedia","wgCentralNoticeCookiesToDelete":[],"wgCentralNoticeCategoriesUsingLegacy":["Fundraising","fundraising"],"wgCategoryTreePageCategoryOptions":"{\"mode\":0,\"hideprefix\":20,\"showcount\":true,\"namespaces\":false}","wgWikibaseItemId":"Q835922","wgCentralAuthMobileDomain":false,"wgCodeMirrorEnabled":false,"wgVisualEditorToolbarScrollOffset":0,"wgVisualEditorUnsupportedEditParams":["undo","undoafter","veswitched"],"wgEditSubmitButtonLabelPublish":false});mw.loader.state({"ext.gadget.charinsert-styles":"ready","ext.globalCssJs.user.styles":"ready","ext.globalCssJs.site.styles":"ready","site.styles":"ready","noscript":"ready","user.styles":"ready","user":"ready","user.options":"ready","user.tokens":"loading","ext.cite.styles":"ready","ext.pygments":"ready","wikibase.client.init":"ready","ext.visualEditor.desktopArticleTarget.noscript":"ready","ext.uls.interlanguage":"ready","ext.wikimediaBadges":"ready","skins.vector.styles.experimental.print":"ready","mediawiki.legacy.shared":"ready","mediawiki.legacy.commonPrint":"ready","mediawiki.sectionAnchor":"ready","mediawiki.skinning.interface":"ready","skins.vector.styles":"ready","ext.globalCssJs.user":"ready","ext.globalCssJs.site":"ready"});mw.loader.implement("user.tokens@1dqfd7l",function ( $, jQuery, require, module ) {/nmw.user.tokens.set({"editToken":"+\\","patrolToken":"+\\","watchToken":"+\\","csrfToken":"+\\"});/*@nomin*//n/n});mw.loader.load(["ext.cite.a11y","site","mediawiki.page.startup","mediawiki.user","mediawiki.hidpi","mediawiki.page.ready","mediawiki.toc","mediawiki.searchSuggest","ext.gadget.teahouse","ext.gadget.ReferenceTooltips","ext.gadget.watchlist-notice","ext.gadget.DRN-wizard","ext.gadget.charinsert","ext.gadget.refToolbar","ext.gadget.extra-toolbar-buttons","ext.gadget.switcher","ext.centralauth.centralautologin","ext.popups","ext.visualEditor.desktopArticleTarget.init","ext.visualEditor.targetLoader","ext.eventLogging.subscriber","ext.wikimediaEvents","ext.navigationTiming","ext.uls.eventlogger","ext.uls.init","ext.uls.interface","ext.centralNotice.geoIP","ext.centralNotice.startUp","skins.vector.js"]);});</script>/n<link rel="stylesheet" href="/w/load.php?debug=false&amp;lang=en&amp;modules=ext.cite.styles%7Cext.pygments%2CwikimediaBadges%7Cext.uls.interlanguage%7Cext.visualEditor.desktopArticleTarget.noscript%7Cmediawiki.legacy.commonPrint%2Cshared%7Cmediawiki.sectionAnchor%7Cmediawiki.skinning.interface%7Cskins.vector.styles%7Cskins.vector.styles.experimental.print%7Cwikibase.client.init&amp;only=styles&amp;skin=vector"/>/n<script async="" src="/w/load.php?debug=false&amp;lang=en&amp;modules=startup&amp;only=scripts&amp;skin=vector"></script>/n<meta name="ResourceLoaderDynamicStyles" content=""/>/n<link rel="stylesheet" href="/w/load.php?debug=false&amp;lang=en&amp;modules=ext.gadget.charinsert-styles&amp;only=styles&amp;skin=vector"/>/n<link rel="stylesheet" href="/w/load.php?debug=false&amp;lang=en&amp;modules=site.styles&amp;only=styles&amp;skin=vector"/>/n<meta name="generator" content="MediaWiki 1.31.0-wmf.4"/>/n<meta name="referrer" content="origin-when-cross-origin"/>/n<link rel="alternate" href="android-app://org.wikipedia/http/en.m.wikipedia.org/wiki/Lexical_analysis"/>/n<link rel="alternate" type="application/x-wiki" title="Edit this page" href="/w/index.php?title=Lexical_analysis&amp;action=edit"/>/n<link rel="edit" title="Edit this page" href="/w/index.php?title=Lexical_analysis&amp;action=edit"/>/n<link rel="apple-touch-icon" href="/static/apple-touch/wikipedia.png"/>/n<link rel="shortcut icon" href="/static/favicon/wikipedia.ico"/>/n<link rel="search" type="application/opensearchdescription+xml" href="/w/opensearch_desc.php" title="Wikipedia (en)"/>/n<link rel="EditURI" type="application/rsd+xml" href="//en.wikipedia.org/w/api.php?action=rsd"/>/n<link rel="license" href="//creativecommons.org/licenses/by-sa/3.0/"/>/n<link rel="canonical" href="https://en.wikipedia.org/wiki/Lexical_analysis"/>/n<link rel="dns-prefetch" href="//login.wikimedia.org"/>/n<link rel="dns-prefetch" href="//meta.wikimedia.org" />/n<!--[if lt IE 9]><script src="/w/load.php?debug=false&amp;lang=en&amp;modules=html5shiv&amp;only=scripts&amp;skin=vector&amp;sync=1"></script><![endif]-->/n</head>/n<body class="mediawiki ltr sitedir-ltr mw-hide-empty-elt ns-0 ns-subject page-Lexical_analysis rootpage-Lexical_analysis vector-experimental-print-styles vector-nav-directionality skin-vector action-view">		<div id="mw-page-base" class="noprint"></div>/n		<div id="mw-head-base" class="noprint"></div>/n		<div id="content" class="mw-body" role="main">/n			<a id="top"></a>/n/n							<div id="siteNotice" class="mw-body-content"><!-- CentralNotice --></div>/n						<div class="mw-indicators mw-body-content">/n</div>/n			<h1 id="firstHeading" class="firstHeading" lang="en">Lexical analysis</h1>/n									<div id="bodyContent" class="mw-body-content">/n									<div id="siteSub" class="noprint">From Wikipedia, the free encyclopedia</div>/n								<div id="contentSub"></div>/n												<div id="jump-to-nav" class="mw-jump">/n					Jump to:					<a href="#mw-head">navigation</a>, 					<a href="#p-search">search</a>/n				</div>/n				<div id="mw-content-text" lang="en" dir="ltr" class="mw-content-ltr"><div class="mw-parser-output"><div role="note" class="hatnote navigation-not-searchable">"Lexer" redirects here. For people with this name, see <a href="/wiki/Lexer_(surname)" title="Lexer (surname)">Lexer (surname)</a>.</div>/n<p>In <a href="/wiki/Computer_science" title="Computer science">computer science</a>, <b>lexical analysis</b>, <b>lexing</b> or <b>tokenization</b> is the process of converting a sequence of characters (such as in a computer program or web page) into a sequence of tokens (<a href="/wiki/String_(computer_science)" title="String (computer science)">strings</a> with an assigned and thus identified meaning). A program that performs lexical analysis may be termed a <i>lexer</i>, <i>tokenizer</i>,<sup id="cite_ref-1" class="reference"><a href="#cite_note-1">[1]</a></sup> or <i>scanner</i>, though <i>scanner</i> is also a term for the first stage of a lexer. A lexer is generally combined with a <a href="/wiki/Parser" class="mw-redirect" title="Parser">parser</a>, which together analyze the <a href="/wiki/Syntax_(programming_languages)" title="Syntax (programming languages)">syntax of programming languages</a>, web pages, and so forth.</p>/n<p></p>/n<div id="toc" class="toc">/n<div class="toctitle">/n<h2>Contents</h2>/n</div>/n<ul>/n<li class="toclevel-1 tocsection-1"><a href="#Applications"><span class="tocnumber">1</span> <span class="toctext">Applications</span></a></li>/n<li class="toclevel-1 tocsection-2"><a href="#Lexeme"><span class="tocnumber">2</span> <span class="toctext">Lexeme</span></a></li>/n<li class="toclevel-1 tocsection-3"><a href="#Token"><span class="tocnumber">3</span> <span class="toctext">Token</span></a></li>/n<li class="toclevel-1 tocsection-4"><a href="#Lexical_grammar"><span class="tocnumber">4</span> <span class="toctext">Lexical grammar</span></a></li>/n<li class="toclevel-1 tocsection-5"><a href="#Tokenization"><span class="tocnumber">5</span> <span class="toctext">Tokenization</span></a>/n<ul>/n<li class="toclevel-2 tocsection-6"><a href="#Scanner"><span class="tocnumber">5.1</span> <span class="toctext">Scanner</span></a></li>/n<li class="toclevel-2 tocsection-7"><a href="#Evaluator"><span class="tocnumber">5.2</span> <span class="toctext">Evaluator</span></a></li>/n<li class="toclevel-2 tocsection-8"><a href="#Obstacles"><span class="tocnumber">5.3</span> <span class="toctext">Obstacles</span></a></li>/n<li class="toclevel-2 tocsection-9"><a href="#Software"><span class="tocnumber">5.4</span> <span class="toctext">Software</span></a></li>/n</ul>/n</li>/n<li class="toclevel-1 tocsection-10"><a href="#Lexer_generator"><span class="tocnumber">6</span> <span class="toctext">Lexer generator</span></a>/n<ul>/n<li class="toclevel-2 tocsection-11"><a href="#List_of_lexer_generators"><span class="tocnumber">6.1</span> <span class="toctext">List of lexer generators</span></a></li>/n</ul>/n</li>/n<li class="toclevel-1 tocsection-12"><a href="#Phrase_structure"><span class="tocnumber">7</span> <span class="toctext">Phrase structure</span></a>/n<ul>/n<li class="toclevel-2 tocsection-13"><a href="#Line_continuation"><span class="tocnumber">7.1</span> <span class="toctext">Line continuation</span></a></li>/n<li class="toclevel-2 tocsection-14"><a href="#Semicolon_insertion"><span class="tocnumber">7.2</span> <span class="toctext">Semicolon insertion</span></a></li>/n<li class="toclevel-2 tocsection-15"><a href="#Off-side_rule"><span class="tocnumber">7.3</span> <span class="toctext">Off-side rule</span></a></li>/n</ul>/n</li>/n<li class="toclevel-1 tocsection-16"><a href="#Context-sensitive_lexing"><span class="tocnumber">8</span> <span class="toctext">Context-sensitive lexing</span></a></li>/n<li class="toclevel-1 tocsection-17"><a href="#Notes"><span class="tocnumber">9</span> <span class="toctext">Notes</span></a></li>/n<li class="toclevel-1 tocsection-18"><a href="#References"><span class="tocnumber">10</span> <span class="toctext">References</span></a></li>/n<li class="toclevel-1 tocsection-19"><a href="#External_links"><span class="tocnumber">11</span> <span class="toctext">External links</span></a></li>/n</ul>/n</div>/n<p></p>/n<h2><span class="mw-headline" id="Applications">Applications</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Lexical_analysis&amp;action=edit&amp;section=1" title="Edit section: Applications">edit</a><span class="mw-editsection-bracket">]</span></span></h2>/n<p>A lexer forms the first phase of a <a href="/wiki/Compiler_frontend" class="mw-redirect" title="Compiler frontend">compiler frontend</a> in modern processing. Analysis generally occurs in one pass.</p>/n<p>In older languages such as <a href="/wiki/ALGOL" title="ALGOL">ALGOL</a>, the initial stage was instead <a href="/wiki/Line_reconstruction" class="mw-redirect" title="Line reconstruction">line reconstruction</a>, which performed <a href="/wiki/Stropping_(syntax)" title="Stropping (syntax)">unstropping</a> and removed whitespace and <a href="/wiki/Comment_(computer_programming)" title="Comment (computer programming)">comments</a> (and had scannerless parsers, with no separate lexer). These steps are now done as part of the lexer.</p>/n<p>Lexers and parsers are most often used for compilers, but can be used for other computer language tools, such as <a href="/wiki/Prettyprint" title="Prettyprint">prettyprinters</a> or <a href="/wiki/Lint_(software)" title="Lint (software)">linters</a>. Lexing can be divided into two stages: the <i>scanning</i>, which segments the input string into syntactic units called <i>lexemes</i> and categorizes these into token classes; and the <i>evaluating</i>, which converts lexemes into processed values.</p>/n<p>Lexers are generally quite simple, with most of the complexity deferred to the parser or <a href="/wiki/Semantic_analysis_(compilers)" title="Semantic analysis (compilers)">semantic analysis</a> phases, and can often be generated by a <a href="#Lexer_generator">lexer generator</a>, notably <a href="/wiki/Lex_(software)" title="Lex (software)">lex</a> or derivatives. However, lexers can sometimes include some complexity, such as <a href="#Phrase_structure">phrase structure</a> processing to make input easier and simplify the parser, and may be written partly or fully by hand, either to support more features or for performance.</p>/n<h2><span class="mw-headline" id="Lexeme">Lexeme</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Lexical_analysis&amp;action=edit&amp;section=2" title="Edit section: Lexeme">edit</a><span class="mw-editsection-bracket">]</span></span></h2>/n<p>A <i>lexeme</i> is a sequence of characters in the source program that matches the pattern for a token and is identified by the lexical analyzer as an instance of that token.<sup id="cite_ref-2" class="reference"><a href="#cite_note-2">[2]</a></sup></p>/n<p>Some authors term this a "token", using "token" interchangeably to represent the string being tokenized, and the token data structure resulting from putting this string through the <a href="#Tokenization">tokenization</a> process.<sup id="cite_ref-3" class="reference"><a href="#cite_note-3">[3]</a></sup><sup id="cite_ref-4" class="reference"><a href="#cite_note-4">[4]</a></sup></p>/n<p>The word lexeme in computer science is defined differently than <a href="/wiki/Lexeme" title="Lexeme">lexeme</a> in linguistics. A lexeme in computer science roughly corresponds to what might be termed a <a href="/wiki/Word" title="Word">word</a> in linguistics (the term <a href="/wiki/Word_(computer_architecture)" title="Word (computer architecture)">word</a> in computer science has a different meaning than <a href="/wiki/Word" title="Word">word</a> in linguistics), although in some cases it may be more similar to a <a href="/wiki/Morpheme" title="Morpheme">morpheme</a>.</p>/n<h2><span class="mw-headline" id="Token">Token</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Lexical_analysis&amp;action=edit&amp;section=3" title="Edit section: Token">edit</a><span class="mw-editsection-bracket">]</span></span></h2>/n<p>A <i>lexical token</i> or simply <i>token</i> is a pair consisting of a <i>token name</i> and an optional <i>token value</i>. The token name is a category of lexical unit.<sup id="cite_ref-5" class="reference"><a href="#cite_note-5">[5]</a></sup> Common token names are</p>/n<ul>/n<li>identifiers: names the programmer chooses;</li>/n<li>keywords: names already in the programming language;</li>/n<li>separators (also known as punctuators): punctuation characters and paired-delimiters;</li>/n<li>operators: symbols that operate on arguments and produce results;</li>/n<li>literals: numeric, logical, textual, reference literals;</li>/n<li>comments: line, block.</li>/n</ul>/n<table class="wikitable">/n<caption>Examples of token values</caption>/n<tr>/n<th>Token name</th>/n<th>Sample token values</th>/n</tr>/n<tr>/n<td>identifier</td>/n<td>x, color, UP</td>/n</tr>/n<tr>/n<td>keyword</td>/n<td>if, while, return</td>/n</tr>/n<tr>/n<td>separator</td>/n<td>}, (,&#160;;</td>/n</tr>/n<tr>/n<td>operator</td>/n<td>+, &lt;, =</td>/n</tr>/n<tr>/n<td>literal</td>/n<td>true, 6.02e23, "music"</td>/n</tr>/n<tr>/n<td>comment</td>/n<td>// must be negative, /* Retrieves user data */</td>/n</tr>/n</table>/n<p>Consider this expression in the <a href="/wiki/C_(programming_language)" title="C (programming language)">C</a> programming language:</p>/n<dl>/n<dd><code>x = a + b * 2;</code></dd>/n</dl>/n<p>The lexical analysis of this expression yields the following sequence of tokens:</p>/n<dl>/n<dd>[(identifier, x), (operator, =), (identifier, a), (operator, +), (identifier, b), (operator, *), (literal, 2), (separator,&#160;;)]</dd>/n</dl>/n<p>A token name is what might be termed a <a href="/wiki/Part_of_speech" title="Part of speech">part of speech</a> in linguistics.</p>/n<h2><span class="mw-headline" id="Lexical_grammar">Lexical grammar</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Lexical_analysis&amp;action=edit&amp;section=4" title="Edit section: Lexical grammar">edit</a><span class="mw-editsection-bracket">]</span></span></h2>/n<div role="note" class="hatnote navigation-not-searchable">Further information: <a href="/wiki/Lexical_grammar" title="Lexical grammar">Lexical grammar</a></div>/n<p>The specification of a <a href="/wiki/Programming_language" title="Programming language">programming language</a> often includes a set of rules, the <a href="/wiki/Lexical_grammar" title="Lexical grammar">lexical grammar</a>, which defines the lexical syntax. The lexical syntax is usually a <a href="/wiki/Regular_language" title="Regular language">regular language</a>, with the grammar rules consisting of <a href="/wiki/Regular_expression" title="Regular expression">regular expressions</a>; they define the set of possible character sequences (lexemes) of a token. A lexer recognizes strings, and for each kind of string found the lexical program takes an action, most simply producing a token.</p>/n<p>Two important common lexical categories are <a href="/wiki/Whitespace_character" title="Whitespace character">white space</a> and <a href="/wiki/Comment_(computer_programming)" title="Comment (computer programming)">comments</a>. These are also defined in the grammar and processed by the lexer, but may be discarded (not producing any tokens) and considered <i>non-significant</i>, at most separating two tokens (as in <code>if&#160;x</code> instead of <code>ifx</code>). There are two important exceptions to this. First, in <a href="/wiki/Off-side_rule" title="Off-side rule">off-side rule</a> languages that delimit <a href="/wiki/Block_(programming)" title="Block (programming)">blocks</a> with indenting, initial whitespace is significant, as it determines block structure, and is generally handled at the lexer level; see <a href="#Phrase_structure">phrase structure</a>, below. Secondly, in some uses of lexers, comments and whitespace must be preserved – for examples, a <a href="/wiki/Prettyprint" title="Prettyprint">prettyprinter</a> also needs to output the comments and some debugging tools may provide messages to the programmer showing the original source code. In the 1960s, notably for <a href="/wiki/ALGOL" title="ALGOL">ALGOL</a>, whitespace and comments were eliminated as part of the <a href="/wiki/Line_reconstruction" class="mw-redirect" title="Line reconstruction">line reconstruction</a> phase (the initial phase of the <a href="/wiki/Compiler_frontend" class="mw-redirect" title="Compiler frontend">compiler frontend</a>), but this separate phase has been eliminated and these are now handled by the lexer.</p>/n<h2><span class="mw-headline" id="Tokenization">Tokenization</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Lexical_analysis&amp;action=edit&amp;section=5" title="Edit section: Tokenization">edit</a><span class="mw-editsection-bracket">]</span></span></h2>/n<p><i>Tokenization</i> is the process of demarcating and possibly classifying sections of a string of input characters. The resulting tokens are then passed on to some other form of processing. The process can be considered a sub-task of <a href="/wiki/Parsing" title="Parsing">parsing</a> input.</p>/n<p>(Note: <i><a href="/wiki/Tokenization_(data_security)" title="Tokenization (data security)">Tokenization</a></i> in the field of computer security has a different meaning.)</p>/n<p>For example, in the text <a href="/wiki/String_(computer_science)" title="String (computer science)">string</a>:</p>/n<dl>/n<dd><code>The quick brown fox jumps over the lazy dog</code></dd>/n</dl>/n<p>the string isn't implicitly segmented on spaces, as a <a href="/wiki/Natural_language" title="Natural language">natural language</a> speaker would do. The raw input, the 43 characters, must be explicitly split into the 9 tokens with a given space delimiter (i.e., matching the string <code>" "</code> or regular expression <code>/\s{1}/</code>).</p>/n<p>The tokens could be represented in <a href="/wiki/XML" title="XML">XML</a>,</p>/n<div class="mw-highlight mw-content-ltr" dir="ltr">/n<pre>/n<span class="nt">&lt;sentence&gt;</span>/n  <span class="nt">&lt;word&gt;</span>The<span class="nt">&lt;/word&gt;</span>/n  <span class="nt">&lt;word&gt;</span>quick<span class="nt">&lt;/word&gt;</span>/n  <span class="nt">&lt;word&gt;</span>brown<span class="nt">&lt;/word&gt;</span>/n  <span class="nt">&lt;word&gt;</span>fox<span class="nt">&lt;/word&gt;</span>/n  <span class="nt">&lt;word&gt;</span>jumps<span class="nt">&lt;/word&gt;</span>/n  <span class="nt">&lt;word&gt;</span>over<span class="nt">&lt;/word&gt;</span>/n  <span class="nt">&lt;word&gt;</span>the<span class="nt">&lt;/word&gt;</span>/n  <span class="nt">&lt;word&gt;</span>lazy<span class="nt">&lt;/word&gt;</span>/n  <span class="nt">&lt;word&gt;</span>dog<span class="nt">&lt;/word&gt;</span>/n<span class="nt">&lt;/sentence&gt;</span>/n</pre></div>/n<p>Or as an <a href="/wiki/S-expression" title="S-expression">s-expression</a>,</p>/n<div class="mw-highlight mw-content-ltr" dir="ltr">/n<pre>/n <span class="p">(</span><span class="nv">sentence</span>/n   <span class="p">(</span><span class="nv">word</span> <span class="nv">The</span><span class="p">)</span>/n   <span class="p">(</span><span class="nv">word</span> <span class="nv">quick</span><span class="p">)</span>/n   <span class="p">(</span><span class="nv">word</span> <span class="nv">brown</span><span class="p">)</span> /n   <span class="p">(</span><span class="nv">word</span> <span class="nv">fox</span><span class="p">)</span>/n   <span class="p">(</span><span class="nv">word</span> <span class="nv">jumps</span><span class="p">)</span>/n   <span class="p">(</span><span class="nv">word</span> <span class="nv">over</span><span class="p">)</span> /n   <span class="p">(</span><span class="nv">word</span> <span class="k">the</span><span class="p">)</span>/n   <span class="p">(</span><span class="nv">word</span> <span class="nv">lazy</span><span class="p">)</span>/n   <span class="p">(</span><span class="nv">word</span> <span class="nv">dog</span><span class="p">))</span>/n</pre></div>/n<p>When a token class represents more than one possible lexeme, the lexer often saves enough information to reproduce the original lexeme, so that it can be used in <a href="/wiki/Semantic_analysis_(compilers)" title="Semantic analysis (compilers)">semantic analysis</a>. The parser typically retrieves this information from the lexer and stores it in the <a href="/wiki/Abstract_syntax_tree" title="Abstract syntax tree">abstract syntax tree</a>. This is necessary in order to avoid information loss in the case of numbers and identifiers.</p>/n<p>Tokens are identified based on the specific rules of the lexer. Some methods used to identify tokens include: <a href="/wiki/Regular_expression" title="Regular expression">regular expressions</a>, specific sequences of characters termed a <a href="/wiki/Flag_(computing)" class="mw-redirect" title="Flag (computing)">flag</a>, specific separating characters called <a href="/wiki/Delimiter" title="Delimiter">delimiters</a>, and explicit definition by a dictionary. Special characters, including punctuation characters, are commonly used by lexers to identify tokens because of their natural use in written and programming languages.</p>/n<p>Tokens are often categorized by character content or by context within the data stream. Categories are defined by the rules of the lexer. Categories often involve grammar elements of the language used in the data stream. Programming languages often categorize tokens as identifiers, operators, grouping symbols, or by <a href="/wiki/Data_type" title="Data type">data type</a>. Written languages commonly categorize tokens as nouns, verbs, adjectives, or punctuation. Categories are used for post-processing of the tokens either by the parser or by other functions in the program.</p>/n<p>A lexical analyzer generally does nothing with combinations of tokens, a task left for a <a href="/wiki/Parser" class="mw-redirect" title="Parser">parser</a>. For example, a typical lexical analyzer recognizes parentheses as tokens, but does nothing to ensure that each "(" is matched with a ")".</p>/n<p>When a lexer feeds tokens to the parser, the representation used is typically an enumerated list of number representations. For example, "Identifier" is represented with 0, "Assignment operator" with 1, "Addition operator" with 2, etc.</p>/n<p>Tokens are defined often by <a href="/wiki/Regular_expression" title="Regular expression">regular expressions</a>, which are understood by a lexical analyzer generator such as <a href="/wiki/Lex_(software)" title="Lex (software)">lex</a>. The lexical analyzer (generated automatically by a tool like lex, or hand-crafted) reads in a stream of characters, identifies the <a href="#Lexeme">lexemes</a> in the stream, and categorizes them into tokens. This is termed <i>tokenizing</i>. If the lexer finds an invalid token, it will report an error.</p>/n<p>Following tokenizing is <a href="/wiki/Parsing" title="Parsing">parsing</a>. From there, the interpreted data may be loaded into data structures for general use, interpretation, or <a href="/wiki/Compiling" class="mw-redirect" title="Compiling">compiling</a>.</p>/n<h3><span class="mw-headline" id="Scanner">Scanner</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Lexical_analysis&amp;action=edit&amp;section=6" title="Edit section: Scanner">edit</a><span class="mw-editsection-bracket">]</span></span></h3>/n<p>The first stage, the <i>scanner</i>, is usually based on a <a href="/wiki/Finite-state_machine" title="Finite-state machine">finite-state machine</a> (FSM). It has encoded within it information on the possible sequences of characters that can be contained within any of the tokens it handles (individual instances of these character sequences are termed <a href="#Lexeme">lexemes</a>). For example, an <i>integer</i> token may contain any sequence of <a href="/wiki/Numerical_digit" title="Numerical digit">numerical digit</a> characters. In many cases, the first non-whitespace character can be used to deduce the kind of token that follows and subsequent input characters are then processed one at a time until reaching a character that is not in the set of characters acceptable for that token (this is termed the <i><a href="/wiki/Maximal_munch" title="Maximal munch">maximal munch</a></i>, or <i>longest match</i>, rule). In some languages, the lexeme creation rules are more complex and may involve <a href="/wiki/Backtracking" title="Backtracking">backtracking</a> over previously read characters. For example, in C, one 'L' character is not enough to distinguish between an identifier that begins with 'L' and a wide-character string literal.</p>/n<h3><span class="mw-headline" id="Evaluator">Evaluator</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Lexical_analysis&amp;action=edit&amp;section=7" title="Edit section: Evaluator">edit</a><span class="mw-editsection-bracket">]</span></span></h3>/n<p>A <a href="#Lexeme">lexeme</a>, however, is only a string of characters known to be of a certain kind (e.g., a string literal, a sequence of letters). In order to construct a token, the lexical analyzer needs a second stage, the <i>evaluator</i>, which goes over the characters of the lexeme to produce a <i>value</i>. The lexeme's type combined with its value is what properly constitutes a token, which can be given to a parser. Some tokens such as parentheses do not really have values, and so the evaluator function for these can return nothing: only the type is needed. Similarly, sometimes evaluators can suppress a lexeme entirely, concealing it from the parser, which is useful for whitespace and comments. The evaluators for identifiers are usually simple (literally representing the identifier), but may include some <a href="/wiki/Stropping_(syntax)" title="Stropping (syntax)">unstropping</a>. The evaluators for <a href="/wiki/Integer_literal" title="Integer literal">integer literals</a> may pass the string on (deferring evaluation to the semantic analysis phase), or may perform evaluation themselves, which can be involved for different bases or floating point numbers. For a simple quoted string literal, the evaluator needs to remove only the quotes, but the evaluator for an <a href="/wiki/String_literal#Escape_sequences" title="String literal">escaped string literal</a> incorporates a lexer, which unescapes the escape sequences.</p>/n<p>For example, in the source code of a computer program, the string</p>/n<dl>/n<dd><code>net_worth_future = (assets - liabilities);</code></dd>/n</dl>/n<p>might be converted into the following lexical token stream; whitespace is suppressed and special characters have no value:</p>/n<pre>/nIDENTIFIER net_worth_future/nEQUALS/nOPEN_PARENTHESIS/nIDENTIFIER assets/nMINUS/nIDENTIFIER liabilities/nCLOSE_PARENTHESIS/nSEMICOLON/n</pre>/n<p>Though it is possible and sometimes necessary, due to licensing restrictions of existing parsers or if the list of tokens is small, to write a lexer by hand, lexers are often generated by automated tools. These tools generally accept regular expressions that describe the tokens allowed in the input stream. Each regular expression is associated with a <a href="/wiki/Formal_grammar#The_syntax_of_grammars" title="Formal grammar">production rule</a> in the lexical grammar of the programming language that evaluates the lexemes matching the regular expression. These tools may generate source code that can be compiled and executed or construct a <a href="/wiki/State_transition_table" title="State transition table">state transition table</a> for a <a href="/wiki/Finite-state_machine" title="Finite-state machine">finite-state machine</a> (which is plugged into template code for compiling and executing).</p>/n<p>Regular expressions compactly represent patterns that the characters in lexemes might follow. For example, for an <a href="/wiki/English_language" title="English language">English</a>-based language, an IDENTIFIER token might be any English alphabetic character or an underscore, followed by any number of instances of ASCII alphanumeric characters and/or underscores. This could be represented compactly by the string <code>[a-zA-Z_][a-zA-Z_0-9]*</code>. This means "any character a-z, A-Z or _, followed by 0 or more of a-z, A-Z, _ or 0-9".</p>/n<p>Regular expressions and the finite-state machines they generate are not powerful enough to handle recursive patterns, such as "<i>n</i> opening parentheses, followed by a statement, followed by <i>n</i> closing parentheses." They are unable to keep count, and verify that <i>n</i> is the same on both sides, unless a finite set of permissible values exists for <i>n</i>. It takes a full parser to recognize such patterns in their full generality. A parser can push parentheses on a stack and then try to pop them off and see if the stack is empty at the end (see example<sup id="cite_ref-6" class="reference"><a href="#cite_note-6">[6]</a></sup> in the <i><a href="/wiki/Structure_and_Interpretation_of_Computer_Programs" title="Structure and Interpretation of Computer Programs">Structure and Interpretation of Computer Programs</a></i> book).</p>/n<h3><span class="mw-headline" id="Obstacles">Obstacles</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Lexical_analysis&amp;action=edit&amp;section=8" title="Edit section: Obstacles">edit</a><span class="mw-editsection-bracket">]</span></span></h3>/n<p>Typically, tokenization occurs at the word level. However, it is sometimes difficult to define what is meant by a "word". Often a tokenizer relies on simple heuristics, for example:</p>/n<ul>/n<li>Punctuation and whitespace may or may not be included in the resulting list of tokens.</li>/n<li>All contiguous strings of alphabetic characters are part of one token; likewise with numbers.</li>/n<li>Tokens are separated by <a href="/wiki/Whitespace_character" title="Whitespace character">whitespace</a> characters, such as a space or line break, or by punctuation characters.</li>/n</ul>/n<p>In languages that use inter-word spaces (such as most that use the Latin alphabet, and most programming languages), this approach is fairly straightforward. However, even here there are many edge cases such as <a href="/wiki/Poetic_contraction" title="Poetic contraction">contractions</a>, <a href="/wiki/Hyphen" title="Hyphen">hyphenated words</a>, <a href="/wiki/Emoticons" class="mw-redirect" title="Emoticons">emoticons</a>, and larger constructs such as <a href="/wiki/URI" class="mw-redirect" title="URI">URIs</a> (which for some purposes may count as single tokens). A classic example is "New York-based", which a naive tokenizer may break at the space even though the better break is (arguably) at the hyphen.</p>/n<p>Tokenization is particularly difficult for languages written in <a href="/wiki/Scriptio_continua" title="Scriptio continua">scriptio continua</a> which exhibit no word boundaries such as <a href="/wiki/Ancient_Greek" title="Ancient Greek">Ancient Greek</a>, <a href="/wiki/Chinese_language" title="Chinese language">Chinese</a>,<sup id="cite_ref-7" class="reference"><a href="#cite_note-7">[7]</a></sup> or <a href="/wiki/Thai_language" title="Thai language">Thai</a>. <a href="/wiki/Agglutinative_language" title="Agglutinative language">Agglutinative languages</a>, such as Korean, also make tokenization tasks complicated.</p>/n<p>Some ways to address the more difficult problems include developing more complex heuristics, querying a table of common special-cases, or fitting the tokens to a <a href="/wiki/Language_model" title="Language model">language model</a> that identifies collocations in a later processing step.</p>/n<h3><span class="mw-headline" id="Software">Software</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Lexical_analysis&amp;action=edit&amp;section=9" title="Edit section: Software">edit</a><span class="mw-editsection-bracket">]</span></span></h3>/n<ul>/n<li><a rel="nofollow" class="external text" href="http://opennlp.apache.org/index.html">Apache OpenNLP</a> includes rule based and statistical tokenizers which support many languages</li>/n<li><a rel="nofollow" class="external text" href="http://tokenizer.tool.uniwits.com">U-Tokenizer</a> is an API over HTTP that can cut Mandarin and Japanese sentences at word boundary. English is supported as well.</li>/n<li><a rel="nofollow" class="external text" href="https://dev.havenondemand.com/apis/tokenizetext#overview">HPE Haven OnDemand Text Tokenization API</a> (Commercial product, with freemium access) uses Advanced Probabilistic Concept Modelling to determine the weight that the term holds in the specified text indexes</li>/n<li>The <a href="/wiki/Lex_(software)" title="Lex (software)">Lex</a> tool and its compiler is designed to generate code for fast lexical analysers based on a formal description of the lexical syntax. It is generally considered insufficient for applications with a complex set of lexical rules and severe performance requirements. For example, the <a href="/wiki/GNU_Compiler_Collection" title="GNU Compiler Collection">GNU Compiler Collection</a> (GCC) uses hand-written lexers.</li>/n</ul>/n<h2><span class="mw-headline" id="Lexer_generator">Lexer generator</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Lexical_analysis&amp;action=edit&amp;section=10" title="Edit section: Lexer generator">edit</a><span class="mw-editsection-bracket">]</span></span></h2>/n<div role="note" class="hatnote navigation-not-searchable">See also: <a href="/wiki/Parser_generator" class="mw-redirect" title="Parser generator">Parser generator</a></div>/n<p>Lexers are often generated by a <i>lexer generator</i>, analogous to <a href="/wiki/Parser_generator" class="mw-redirect" title="Parser generator">parser generators</a>, and such tools often come together. The most established is <a href="/wiki/Lex_(software)" title="Lex (software)">lex</a>, paired with the <a href="/wiki/Yacc" title="Yacc">yacc</a> parser generator, and the free equivalents <a href="/wiki/Flex_lexical_analyser" class="mw-redirect" title="Flex lexical analyser">flex</a>/bison. These generators are a form of <a href="/wiki/Domain-specific_language" title="Domain-specific language">domain-specific language</a>, taking in a lexical specification – generally regular expressions with some markup – and emitting a lexer.</p>/n<p>These tools yield very fast development, which is very important in early development, both to get a working lexer and because a language specification may change often. Further, they often provide advanced features, such as pre- and post-conditions which are hard to program by hand. However, an automatically generated lexer may lack flexibility, and thus may require some manual modification, or an all-manually written lexer.</p>/n<p>Lexer performance is a concern, and optimizing is worthwhile, more so in stable languages where the lexer is run very often (such as C or HTML). lex/flex-generated lexers are reasonably fast, but improvements of two to three times are possible using more tuned generators. Hand-written lexers are sometimes used, but modern lexer generators produce faster lexers than most hand-coded ones. The lex/flex family of generators uses a table-driven approach which is much less efficient than the directly coded approach.<sup class="noprint Inline-Template" style="white-space:nowrap;">[<i><a href="/wiki/Wikipedia:Accuracy_dispute#Disputed_statement" title="Wikipedia:Accuracy dispute"><span title="The material near this tag is possibly inaccurate or nonfactual. (May 2010)">dubious</span></a> <span class="metadata">– <a href="/wiki/Talk:Lexical_analysis#table-driven_vs_directly_coded" title="Talk:Lexical analysis">discuss</a></span></i>]</sup> With the latter approach the generator produces an engine that directly jumps to follow-up states via goto statements. Tools like re2c<sup id="cite_ref-8" class="reference"><a href="#cite_note-8">[8]</a></sup> have proven to produce engines that are between two and three times faster than flex produced engines.<sup class="noprint Inline-Template Template-Fact" style="white-space:nowrap;">[<i><a href="/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed"><span title="This claim needs references to reliable sources. (April 2008)">citation needed</span></a></i>]</sup> It is in general difficult to hand-write analyzers that perform better than engines generated by these latter tools.</p>/n<h3><span class="mw-headline" id="List_of_lexer_generators">List of lexer generators</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Lexical_analysis&amp;action=edit&amp;section=11" title="Edit section: List of lexer generators">edit</a><span class="mw-editsection-bracket">]</span></span></h3>/n<div role="note" class="hatnote navigation-not-searchable">See also: <a href="/wiki/List_of_parser_generators" class="mw-redirect" title="List of parser generators">List of parser generators</a></div>/n<ul>/n<li><a href="/wiki/ANTLR" title="ANTLR">ANTLR</a> – can generate lexical analyzers and parsers</li>/n<li>DFASTAR – generates DFA matrix table-driven lexers in C++</li>/n<li><a href="/wiki/Flex_lexical_analyser" class="mw-redirect" title="Flex lexical analyser">Flex</a> – variant of the classic <i><a href="/wiki/Lex_(software)" title="Lex (software)">lex</a></i> for C/C++</li>/n<li><a href="/wiki/Ragel" title="Ragel">Ragel</a> – state machine and lexer generator with output in C, C++, <a href="/wiki/C_Sharp_(programming_language)" title="C Sharp (programming language)">C#</a>, <a href="/wiki/Objective-C" title="Objective-C">Objective-C</a>, <a href="/wiki/D_(programming_language)" title="D (programming language)">D</a>, <a href="/wiki/Java_(programming_language)" title="Java (programming language)">Java</a>, <a href="/wiki/Go_(programming_language)" title="Go (programming language)">Go</a>, and <a href="/wiki/Ruby_(programming_language)" title="Ruby (programming language)">Ruby</a></li>/n<li><a href="/wiki/Re2c" title="Re2c">re2c</a> – lexer generator for <a href="/wiki/C_(programming_language)" title="C (programming language)">C</a> and <a href="/wiki/C%2B%2B" title="C++">C++</a></li>/n</ul>/n<p>The following lexical analysers can handle <a href="/wiki/Unicode" title="Unicode">Unicode</a>:</p>/n<ul>/n<li><a href="/wiki/JavaCC" title="JavaCC">JavaCC</a> – generates lexical analyzers written in Java</li>/n<li>JFLex – lexical analyzer generator for Java</li>/n<li>AnnoFlex - annotation-based code generator for lexical scanners for Java</li>/n<li>RE/flex - a fast variant of lex/flex for C++ generates scanners with tables or direct code</li>/n<li><a rel="nofollow" class="external text" href="http://quex.sourceforge.net/">Quex</a> – fast universal lexical analyzer generator for C and C++ written in Python</li>/n<li>FsLex – lexer generator for byte and Unicode character input for F#</li>/n<li><a href="/wiki/Re2c" title="Re2c">re2c</a> – lexer generator for <a href="/wiki/C_(programming_language)" title="C (programming language)">C</a> and <a href="/wiki/C%2B%2B" title="C++">C++</a><sup id="cite_ref-9" class="reference"><a href="#cite_note-9">[9]</a></sup></li>/n<li><a href="/wiki/PLY_(Python_Lex-Yacc)" title="PLY (Python Lex-Yacc)">PLY</a> - the Python module ply.lex enables the lexical analysis part</li>/n</ul>/n<h2><span class="mw-headline" id="Phrase_structure">Phrase structure</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Lexical_analysis&amp;action=edit&amp;section=12" title="Edit section: Phrase structure">edit</a><span class="mw-editsection-bracket">]</span></span></h2>/n<p>Lexical analysis mainly segments the input stream of characters into tokens, simply grouping the characters into pieces and categorizing them. However, the lexing may be significantly more complex; most simply, lexers may omit tokens or insert added tokens. Omitting tokens, notably whitespace and comments, is very common, when these are not needed by the compiler. Less commonly, added tokens may be inserted. This is done mainly to group tokens into <a href="/wiki/Statement_(computer_science)" title="Statement (computer science)">statements</a>, or statements into blocks, to simplify the parser.</p>/n<h3><span class="mw-headline" id="Line_continuation">Line continuation</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Lexical_analysis&amp;action=edit&amp;section=13" title="Edit section: Line continuation">edit</a><span class="mw-editsection-bracket">]</span></span></h3>/n<p><a href="/wiki/Line_continuation" class="mw-redirect" title="Line continuation">Line continuation</a> is a feature of some languages where a newline is normally a statement terminator. Most often, ending a line with a backslash (immediately followed by a <a href="/wiki/Newline" title="Newline">newline</a>) results in the line being <i>continued</i> – the following line is <i>joined</i> to the prior line. This is generally done in the lexer: the backslash and newline are discarded, rather than the newline being tokenized. Examples include <a href="/wiki/Bash_(Unix_shell)" title="Bash (Unix shell)">bash</a>,<sup id="cite_ref-10" class="reference"><a href="#cite_note-10">[10]</a></sup> other shell scripts and Python.<sup id="cite_ref-11" class="reference"><a href="#cite_note-11">[11]</a></sup></p>/n<h3><span class="mw-headline" id="Semicolon_insertion">Semicolon insertion</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Lexical_analysis&amp;action=edit&amp;section=14" title="Edit section: Semicolon insertion">edit</a><span class="mw-editsection-bracket">]</span></span></h3>/n<p>Many languages use the semicolon as a statement terminator. Most often this is mandatory, but in some languages the semicolon is optional in many contexts. This is mainly done at the lexer level, where the lexer outputs a semicolon into the token stream, despite one not being present in the input character stream, and is termed <i>semicolon insertion</i> or <i>automatic semicolon insertion</i>. In these cases, semicolons are part of the formal phrase grammar of the language, but may not be found in input text, as they can be inserted by the lexer. Optional semicolons or other terminators or separators are also sometimes handled at the parser level, notably in the case of <a href="/wiki/Trailing_comma" class="mw-redirect" title="Trailing comma">trailing commas</a> or semicolons.</p>/n<p>Semicolon insertion is a feature of <a href="/wiki/BCPL" title="BCPL">BCPL</a> and its distant descendent <a href="/wiki/Go_(programming_language)" title="Go (programming language)">Go</a>,<sup id="cite_ref-12" class="reference"><a href="#cite_note-12">[12]</a></sup> though it is absent in B or C.<sup id="cite_ref-13" class="reference"><a href="#cite_note-13">[13]</a></sup> Semicolon insertion is present in <a href="/wiki/JavaScript" title="JavaScript">JavaScript</a>, though the rules are somewhat complex and much-criticized; to avoid bugs, some recommend always using semicolons, while others use initial semicolons, termed <a href="/wiki/Defensive_semicolon" class="mw-redirect" title="Defensive semicolon">defensive semicolons</a>, at the start of potentially ambiguous statements.</p>/n<p>Semicolon insertion (in languages with semicolon-terminated statements) and line continuation (in languages with newline-terminated statements) can be seen as complementary: semicolon insertion adds a token, even though newlines generally do <i>not</i> generate tokens, while line continuation prevents a token from being generated, even though newlines generally <i>do</i> generate tokens.</p>/n<h3><span class="mw-headline" id="Off-side_rule">Off-side rule</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Lexical_analysis&amp;action=edit&amp;section=15" title="Edit section: Off-side rule">edit</a><span class="mw-editsection-bracket">]</span></span></h3>/n<div role="note" class="hatnote navigation-not-searchable">Further information: <a href="/wiki/Off-side_rule" title="Off-side rule">Off-side rule</a></div>/n<p>The <a href="/wiki/Off-side_rule" title="Off-side rule">off-side rule</a> (blocks determined by indenting) can be implemented in the lexer, as in <a href="/wiki/Python_(programming_language)" title="Python (programming language)">Python</a>, where increasing the indenting results in the lexer emitting an INDENT token, and decreasing the indenting results in the lexer emitting a DEDENT token.<sup id="cite_ref-14" class="reference"><a href="#cite_note-14">[14]</a></sup> These tokens correspond to the opening brace <code>{</code> and closing brace <code>}</code> in languages that use braces for blocks, and means that the phrase grammar does not depend on whether braces or indenting are used. This requires that the lexer hold state, namely the current indent level, and thus can detect changes in indenting when this changes, and thus the lexical grammar is not context-free: INDENT–DEDENT depend on the contextual information of prior indent level.</p>/n<h2><span class="mw-headline" id="Context-sensitive_lexing">Context-sensitive lexing</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Lexical_analysis&amp;action=edit&amp;section=16" title="Edit section: Context-sensitive lexing">edit</a><span class="mw-editsection-bracket">]</span></span></h2>/n<p>Generally lexical grammars are context-free, or almost so, and thus require no looking back or ahead, or backtracking, which allows a simple, clean, and efficient implementation. This also allows simple one-way communication from lexer to parser, without needing any information flowing back to the lexer.</p>/n<p>There are exceptions, however. Simple examples include: semicolon insertion in Go, which requires looking back one token; concatenation of consecutive string literals in Python,<sup id="cite_ref-15" class="reference"><a href="#cite_note-15">[15]</a></sup> which requires holding one token in a buffer before emitting it (to see if the next token is another string literal); and the off-side rule in Python, which requires maintaining a count of indent level (indeed, a stack of each indent level). These examples all only require lexical context, and while they complicate a lexer somewhat, they are invisible to the parser and later phases.</p>/n<p>A more complex example is <a href="/wiki/The_lexer_hack" title="The lexer hack">the lexer hack</a> in C, where the token class of a sequence of characters cannot be determined until the semantic analysis phase, since typedef names and variable names are lexically identical but constitute different token classes. Thus in the hack, the lexer calls the semantic analyzer (say, symbol table) and checks if the sequence requires a typedef name. In this case, information must flow back not from the parser only, but from the semantic analyzer back to the lexer, which complicates design.</p>/n<h2><span class="mw-headline" id="Notes">Notes</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Lexical_analysis&amp;action=edit&amp;section=17" title="Edit section: Notes">edit</a><span class="mw-editsection-bracket">]</span></span></h2>/n<div class="reflist" style="list-style-type: lower-alpha;"></div>/n<h2><span class="mw-headline" id="References">References</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Lexical_analysis&amp;action=edit&amp;section=18" title="Edit section: References">edit</a><span class="mw-editsection-bracket">]</span></span></h2>/n<div class="reflist" style="list-style-type: decimal;">/n<div class="mw-references-wrap mw-references-columns">/n<ol class="references">/n<li id="cite_note-1"><span class="mw-cite-backlink"><b><a href="#cite_ref-1">^</a></b></span> <span class="reference-text"><a rel="nofollow" class="external text" href="http://www.cs.man.ac.uk/~pjj/farrell/comp3.html">www.cs.man.ac.uk</a></span></li>/n<li id="cite_note-2"><span class="mw-cite-backlink"><b><a href="#cite_ref-2">^</a></b></span> <span class="reference-text">page 111, "Compilers Principles, Techniques, &amp; Tools, 2nd Ed." (WorldCat) by Aho, Lam, Sethi and Ullman, as quoted in <a rel="nofollow" class="external free" href="https://stackoverflow.com/questions/14954721/what-is-the-difference-between-token-and-lexeme">https://stackoverflow.com/questions/14954721/what-is-the-difference-between-token-and-lexeme</a></span></li>/n<li id="cite_note-3"><span class="mw-cite-backlink"><b><a href="#cite_ref-3">^</a></b></span> <span class="reference-text"><cite class="citation web">Perl 5 Porters. <a rel="nofollow" class="external text" href="http://perldoc.perl.org/perlinterp.html#Parsing">"perlinterp: Perl 5 version 24.0 documentation"</a>. <i>perldoc.perl.org - Official documentation for the Perl programming language</i>. perldoc.perl.org<span class="reference-accessdate">. Retrieved <span class="nowrap">26 January</span> 2017</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALexical+analysis&amp;rft.atitle=perlinterp%3A+Perl+5+version+24.0+documentation&amp;rft.au=Perl+5+Porters&amp;rft.genre=unknown&amp;rft.jtitle=perldoc.perl.org+-+Official+documentation+for+the+Perl+programming+language&amp;rft_id=http%3A%2F%2Fperldoc.perl.org%2Fperlinterp.html%23Parsing&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal" class="Z3988"><span style="display:none;">&#160;</span></span></span></li>/n<li id="cite_note-4"><span class="mw-cite-backlink"><b><a href="#cite_ref-4">^</a></b></span> <span class="reference-text"><cite class="citation web">Guy Coder (19 February 2013). <a rel="nofollow" class="external text" href="https://stackoverflow.com/questions/14954721/what-is-the-difference-between-token-and-lexeme#comment20999371_14958865">"What is the difference between token and lexeme?"</a>. <i>Stack Overflow</i>. Stack Exchange Inc<span class="reference-accessdate">. Retrieved <span class="nowrap">26 January</span> 2017</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALexical+analysis&amp;rft.atitle=What+is+the+difference+between+token+and+lexeme%3F&amp;rft.au=Guy+Coder&amp;rft.date=2013-02-19&amp;rft.genre=unknown&amp;rft.jtitle=Stack+Overflow&amp;rft_id=https%3A%2F%2Fstackoverflow.com%2Fquestions%2F14954721%2Fwhat-is-the-difference-between-token-and-lexeme%23comment20999371_14958865&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal" class="Z3988"><span style="display:none;">&#160;</span></span></span></li>/n<li id="cite_note-5"><span class="mw-cite-backlink"><b><a href="#cite_ref-5">^</a></b></span> <span class="reference-text">page 111, "Compilers Principles, Techniques, &amp; Tools, 2nd Ed." (WorldCat) by Aho, Lam, Sethi and Ullman, as quoted in <a rel="nofollow" class="external free" href="https://stackoverflow.com/questions/14954721/what-is-the-difference-between-token-and-lexeme">https://stackoverflow.com/questions/14954721/what-is-the-difference-between-token-and-lexeme</a></span></li>/n<li id="cite_note-6"><span class="mw-cite-backlink"><b><a href="#cite_ref-6">^</a></b></span> <span class="reference-text"><a rel="nofollow" class="external text" href="http://mitpress.mit.edu/sicp/full-text/book/book-Z-H-31.html#%_sec_5.1.4">mitpress.mit.edu</a></span></li>/n<li id="cite_note-7"><span class="mw-cite-backlink"><b><a href="#cite_ref-7">^</a></b></span> <span class="reference-text">Huang, C., Simon, P., Hsieh, S., &amp; Prevot, L. (2007) <a rel="nofollow" class="external text" href="http://www.aclweb.org/anthology/P/P07/P07-2018.pdf">Rethinking Chinese Word Segmentation: Tokenization, Character Classification, or Word break Identification</a></span></li>/n<li id="cite_note-8"><span class="mw-cite-backlink"><b><a href="#cite_ref-8">^</a></b></span> <span class="reference-text"><cite class="citation journal">Bumbulis, P.; Cowan, D. D. (Mar–Dec 1993). "RE2C: A more versatile scanner generator". <i>ACM Letters on Programming Languages and Systems</i>. <b>2</b> (1–4): 70–84. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="//doi.org/10.1145%2F176454.176487">10.1145/176454.176487</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALexical+analysis&amp;rft.atitle=RE2C%3A+A+more+versatile+scanner+generator&amp;rft.au=Cowan%2C+D.+D.&amp;rft.aufirst=P.&amp;rft.aulast=Bumbulis&amp;rft.date=1993-03%2F1993-12&amp;rft.genre=article&amp;rft.issue=1%E2%80%934&amp;rft.jtitle=ACM+Letters+on+Programming+Languages+and+Systems&amp;rft.pages=70-84&amp;rft.volume=2&amp;rft_id=info%3Adoi%2F10.1145%2F176454.176487&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal" class="Z3988"><span style="display:none;">&#160;</span></span></span></li>/n<li id="cite_note-9"><span class="mw-cite-backlink"><b><a href="#cite_ref-9">^</a></b></span> <span class="reference-text"><a rel="nofollow" class="external autonumber" href="http://re2c.org/manual/features/encodings/encodings.html">[1]</a>, re2c manual</span></li>/n<li id="cite_note-10"><span class="mw-cite-backlink"><b><a href="#cite_ref-10">^</a></b></span> <span class="reference-text"><i><a rel="nofollow" class="external text" href="https://www.gnu.org/software/bash/manual/bashref.html">Bash Reference Manual</a></i>, <a rel="nofollow" class="external text" href="https://www.gnu.org/software/bash/manual/bashref.html#Escape-Character">3.1.2.1 Escape Character</a></span></li>/n<li id="cite_note-11"><span class="mw-cite-backlink"><b><a href="#cite_ref-11">^</a></b></span> <span class="reference-text"><a rel="nofollow" class="external text" href="https://docs.python.org/">Python Documentation</a>, <a rel="nofollow" class="external text" href="https://docs.python.org/3/reference/lexical_analysis.html">2. Lexical analysis</a>: <a rel="nofollow" class="external text" href="https://docs.python.org/3/reference/lexical_analysis.html#explicit-line-joining">2.1.5. Explicit line joining</a></span></li>/n<li id="cite_note-12"><span class="mw-cite-backlink"><b><a href="#cite_ref-12">^</a></b></span> <span class="reference-text"><i><a rel="nofollow" class="external text" href="http://golang.org/doc/effective_go.html">Effective Go</a></i>, "<a rel="nofollow" class="external text" href="http://golang.org/doc/effective_go.html#semicolons">Semicolons</a>"</span></li>/n<li id="cite_note-13"><span class="mw-cite-backlink"><b><a href="#cite_ref-13">^</a></b></span> <span class="reference-text">"<a rel="nofollow" class="external text" href="https://groups.google.com/forum/#!topic/golang-nuts/XuMrWI0Q8uk">Semicolons in Go</a>", golang-nuts, Rob 'Commander' Pike, 12/10/09</span></li>/n<li id="cite_note-14"><span class="mw-cite-backlink"><b><a href="#cite_ref-14">^</a></b></span> <span class="reference-text"><a rel="nofollow" class="external text" href="https://docs.python.org/">Python Documentation</a>, <a rel="nofollow" class="external text" href="https://docs.python.org/3/reference/lexical_analysis.html">2. Lexical analysis</a>: <a rel="nofollow" class="external text" href="https://docs.python.org/3/reference/lexical_analysis.html#indentation">2.1.8. Indentation</a></span></li>/n<li id="cite_note-15"><span class="mw-cite-backlink"><b><a href="#cite_ref-15">^</a></b></span> <span class="reference-text"><a rel="nofollow" class="external text" href="https://docs.python.org/">Python Documentation</a>, <a rel="nofollow" class="external text" href="https://docs.python.org/3/reference/lexical_analysis.html">2. Lexical analysis</a>: <a rel="nofollow" class="external text" href="https://docs.python.org/3/reference/lexical_analysis.html#string-literal-concatenation">2.4.2. String literal concatenation</a></span></li>/n</ol>/n</div>/n</div>/n<div class="refbegin" style="">/n<ul>/n<li><i>Compiling with C# and Java</i>, Pat Terry, 2005, <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/032126360X" title="Special:BookSources/032126360X">032126360X</a></li>/n<li><i>Algorithms + Data Structures = Programs</i>, Niklaus Wirth, 1975, <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/0-13-022418-9" title="Special:BookSources/0-13-022418-9">0-13-022418-9</a></li>/n<li><i>Compiler Construction</i>, Niklaus Wirth, 1996, <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/0-201-40353-6" title="Special:BookSources/0-201-40353-6">0-201-40353-6</a></li>/n<li>Sebesta, R. W. (2006). Concepts of programming languages (Seventh edition) pp.&#160;177. Boston: Pearson/Addison-Wesley.</li>/n</ul>/n</div>/n<h2><span class="mw-headline" id="External_links">External links</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Lexical_analysis&amp;action=edit&amp;section=19" title="Edit section: External links">edit</a><span class="mw-editsection-bracket">]</span></span></h2>/n<ul>/n<li><cite class="citation journal">Yang, W.; Tsay, Chey-Woei; Chan, Jien-Tsai (2002). <a rel="nofollow" class="external text" href="http://people.cs.nctu.edu.tw/~wuuyang/homepage/papers/applicability2002.ps">"On the applicability of the longest-match rule in lexical analysis"</a>. <i>Computer Languages, Systems and Structures</i>. Elsevier Science. <b>28</b> (3): 273–288. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="//doi.org/10.1016%2FS0096-0551%2802%2900014-0">10.1016/S0096-0551(02)00014-0</a>. NSC 86-2213-E-009-021 and NSC 86-2213-E-009-079.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALexical+analysis&amp;rft.atitle=On+the+applicability+of+the+longest-match+rule+in+lexical+analysis&amp;rft.au=Chan%2C+Jien-Tsai&amp;rft.au=Tsay%2C+Chey-Woei&amp;rft.aufirst=W.&amp;rft.aulast=Yang&amp;rft.date=2002&amp;rft.genre=article&amp;rft.issue=3&amp;rft.jtitle=Computer+Languages%2C+Systems+and+Structures&amp;rft.pages=273-288&amp;rft.volume=28&amp;rft_id=http%3A%2F%2Fpeople.cs.nctu.edu.tw%2F~wuuyang%2Fhomepage%2Fpapers%2Fapplicability2002.ps&amp;rft_id=info%3Adoi%2F10.1016%2FS0096-0551%2802%2900014-0&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal" class="Z3988"><span style="display:none;">&#160;</span></span></li>/n<li><cite class="citation web">Trim, Craig (Jan 23, 2013). <a rel="nofollow" class="external text" href="https://www.ibm.com/developerworks/community/blogs/nlp/entry/tokenization">"The Art of Tokenization"</a>. <i>Developer Works</i>. IBM.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALexical+analysis&amp;rft.atitle=The+Art+of+Tokenization&amp;rft.aufirst=Craig&amp;rft.aulast=Trim&amp;rft.date=2013-01-23&amp;rft.genre=unknown&amp;rft.jtitle=Developer+Works&amp;rft_id=https%3A%2F%2Fwww.ibm.com%2Fdeveloperworks%2Fcommunity%2Fblogs%2Fnlp%2Fentry%2Ftokenization&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal" class="Z3988"><span style="display:none;">&#160;</span></span></li>/n<li><a rel="nofollow" class="external text" href="http://www.gabormelli.com/RKB/Word_Mention_Segmentation_Task">Word Mention Segmentation Task</a>, an analysis</li>/n</ul>/n/n/n<!-- /nNewPP limit report/nParsed by mw1285/nCached time: 20171026155002/nCache expiry: 1900800/nDynamic content: false/nCPU time usage: 0.216 seconds/nReal time usage: 0.285 seconds/nPreprocessor visited node count: 1697/1000000/nPreprocessor generated node count: 0/1500000/nPost‐expand include size: 18113/2097152 bytes/nTemplate argument size: 2531/2097152 bytes/nHighest expansion depth: 15/40/nExpensive parser function count: 3/500/nLua time usage: 0.098/10.000 seconds/nLua memory usage: 3.05 MB/50 MB/n-->/n<!--/nTransclusion expansion time report (%,ms,calls,template)/n100.00%  249.120      1 -total/n 30.81%   76.760      2 Template:Reflist/n 22.02%   54.853      3 Template:Cite_web/n 21.84%   54.417      2 Template:Fix/n 16.89%   42.079      1 Template:Dubious/n 11.66%   29.041      1 Template:Redirect/n 11.39%   28.377      3 Template:Category_handler/n 11.23%   27.987      3 Template:ISBN/n  8.96%   22.318      2 Template:Delink/n  7.38%   18.396      1 Template:Citation_needed/n-->/n</div>/n<!-- Saved in parser cache with key enwiki:pcache:idhash:81251-0!canonical and timestamp 20171026155008 and revision id 807206513/n -->/n<noscript><img src="//en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1" alt="" title="" width="1" height="1" style="border: none; position: absolute;" /></noscript></div>					<div class="printfooter">/n						Retrieved from "<a dir="ltr" href="https://en.wikipedia.org/w/index.php?title=Lexical_analysis&amp;oldid=807206513">https://en.wikipedia.org/w/index.php?title=Lexical_analysis&amp;oldid=807206513</a>"					</div>/n				<div id="catlinks" class="catlinks" data-mw="interface"><div id="mw-normal-catlinks" class="mw-normal-catlinks"><a href="/wiki/Help:Category" title="Help:Category">Categories</a>: <ul><li><a href="/wiki/Category:Compiler_construction" title="Category:Compiler construction">Compiler construction</a></li><li><a href="/wiki/Category:Programming_language_implementation" title="Category:Programming language implementation">Programming language implementation</a></li><li><a href="/wiki/Category:Parsing" title="Category:Parsing">Parsing</a></li></ul></div><div id="mw-hidden-catlinks" class="mw-hidden-catlinks mw-hidden-cats-hidden">Hidden categories: <ul><li><a href="/wiki/Category:All_accuracy_disputes" title="Category:All accuracy disputes">All accuracy disputes</a></li><li><a href="/wiki/Category:Articles_with_disputed_statements_from_May_2010" title="Category:Articles with disputed statements from May 2010">Articles with disputed statements from May 2010</a></li><li><a href="/wiki/Category:All_articles_with_unsourced_statements" title="Category:All articles with unsourced statements">All articles with unsourced statements</a></li><li><a href="/wiki/Category:Articles_with_unsourced_statements_from_April_2008" title="Category:Articles with unsourced statements from April 2008">Articles with unsourced statements from April 2008</a></li></ul></div></div>				<div class="visualClear"></div>/n							</div>/n		</div>/n		<div id="mw-navigation">/n			<h2>Navigation menu</h2>/n/n			<div id="mw-head">/n									<div id="p-personal" role="navigation" class="" aria-labelledby="p-personal-label">/n						<h3 id="p-personal-label">Personal tools</h3>/n						<ul>/n							<li id="pt-anonuserpage">Not logged in</li><li id="pt-anontalk"><a href="/wiki/Special:MyTalk" title="Discussion about edits from this IP address [n]" accesskey="n">Talk</a></li><li id="pt-anoncontribs"><a href="/wiki/Special:MyContributions" title="A list of edits made from this IP address [y]" accesskey="y">Contributions</a></li><li id="pt-createaccount"><a href="/w/index.php?title=Special:CreateAccount&amp;returnto=Lexical+analysis" title="You are encouraged to create an account and log in; however, it is not mandatory">Create account</a></li><li id="pt-login"><a href="/w/index.php?title=Special:UserLogin&amp;returnto=Lexical+analysis" title="You're encouraged to log in; however, it's not mandatory. [o]" accesskey="o">Log in</a></li>						</ul>/n					</div>/n									<div id="left-navigation">/n										<div id="p-namespaces" role="navigation" class="vectorTabs" aria-labelledby="p-namespaces-label">/n						<h3 id="p-namespaces-label">Namespaces</h3>/n						<ul>/n														<li id="ca-nstab-main" class="selected"><span><a href="/wiki/Lexical_analysis" title="View the content page [c]" accesskey="c">Article</a></span></li>/n							<li id="ca-talk"><span><a href="/wiki/Talk:Lexical_analysis" rel="discussion" title="Discussion about the content page [t]" accesskey="t">Talk</a></span></li>/n						</ul>/n					</div>/n										<div id="p-variants" role="navigation" class="vectorMenu emptyPortlet" aria-labelledby="p-variants-label">/n												<h3 id="p-variants-label">/n							<span>Variants</span>/n						</h3>/n/n						<div class="menu">/n							<ul>/n															</ul>/n						</div>/n					</div>/n									</div>/n				<div id="right-navigation">/n										<div id="p-views" role="navigation" class="vectorTabs" aria-labelledby="p-views-label">/n						<h3 id="p-views-label">Views</h3>/n						<ul>/n														<li id="ca-view" class="collapsible selected"><span><a href="/wiki/Lexical_analysis">Read</a></span></li>/n							<li id="ca-edit" class="collapsible"><span><a href="/w/index.php?title=Lexical_analysis&amp;action=edit" title="Edit this page [e]" accesskey="e">Edit</a></span></li>/n							<li id="ca-history" class="collapsible"><span><a href="/w/index.php?title=Lexical_analysis&amp;action=history" title="Past revisions of this page [h]" accesskey="h">View history</a></span></li>/n						</ul>/n					</div>/n										<div id="p-cactions" role="navigation" class="vectorMenu emptyPortlet" aria-labelledby="p-cactions-label">/n						<h3 id="p-cactions-label"><span>More</span></h3>/n/n						<div class="menu">/n							<ul>/n															</ul>/n						</div>/n					</div>/n										<div id="p-search" role="search">/n						<h3>/n							<label for="searchInput">Search</label>/n						</h3>/n/n						<form action="/w/index.php" id="searchform">/n							<div id="simpleSearch">/n							<input type="search" name="search" placeholder="Search Wikipedia" title="Search Wikipedia [f]" accesskey="f" id="searchInput"/><input type="hidden" value="Special:Search" name="title"/><input type="submit" name="fulltext" value="Search" title="Search Wikipedia for this text" id="mw-searchButton" class="searchButton mw-fallbackSearchButton"/><input type="submit" name="go" value="Go" title="Go to a page with this exact name if it exists" id="searchButton" class="searchButton"/>							</div>/n						</form>/n					</div>/n									</div>/n			</div>/n			<div id="mw-panel">/n				<div id="p-logo" role="banner"><a class="mw-wiki-logo" href="/wiki/Main_Page"  title="Visit the main page"></a></div>/n						<div class="portal" role="navigation" id='p-navigation' aria-labelledby='p-navigation-label'>/n			<h3 id='p-navigation-label'>Navigation</h3>/n/n			<div class="body">/n									<ul>/n						<li id="n-mainpage-description"><a href="/wiki/Main_Page" title="Visit the main page [z]" accesskey="z">Main page</a></li><li id="n-contents"><a href="/wiki/Portal:Contents" title="Guides to browsing Wikipedia">Contents</a></li><li id="n-featuredcontent"><a href="/wiki/Portal:Featured_content" title="Featured content – the best of Wikipedia">Featured content</a></li><li id="n-currentevents"><a href="/wiki/Portal:Current_events" title="Find background information on current events">Current events</a></li><li id="n-randompage"><a href="/wiki/Special:Random" title="Load a random article [x]" accesskey="x">Random article</a></li><li id="n-sitesupport"><a href="https://donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&amp;utm_medium=sidebar&amp;utm_campaign=C13_en.wikipedia.org&amp;uselang=en" title="Support us">Donate to Wikipedia</a></li><li id="n-shoplink"><a href="//shop.wikimedia.org" title="Visit the Wikipedia store">Wikipedia store</a></li>					</ul>/n							</div>/n		</div>/n			<div class="portal" role="navigation" id='p-interaction' aria-labelledby='p-interaction-label'>/n			<h3 id='p-interaction-label'>Interaction</h3>/n/n			<div class="body">/n									<ul>/n						<li id="n-help"><a href="/wiki/Help:Contents" title="Guidance on how to use and edit Wikipedia">Help</a></li><li id="n-aboutsite"><a href="/wiki/Wikipedia:About" title="Find out about Wikipedia">About Wikipedia</a></li><li id="n-portal"><a href="/wiki/Wikipedia:Community_portal" title="About the project, what you can do, where to find things">Community portal</a></li><li id="n-recentchanges"><a href="/wiki/Special:RecentChanges" title="A list of recent changes in the wiki [r]" accesskey="r">Recent changes</a></li><li id="n-contactpage"><a href="//en.wikipedia.org/wiki/Wikipedia:Contact_us" title="How to contact Wikipedia">Contact page</a></li>					</ul>/n							</div>/n		</div>/n			<div class="portal" role="navigation" id='p-tb' aria-labelledby='p-tb-label'>/n			<h3 id='p-tb-label'>Tools</h3>/n/n			<div class="body">/n									<ul>/n						<li id="t-whatlinkshere"><a href="/wiki/Special:WhatLinksHere/Lexical_analysis" title="List of all English Wikipedia pages containing links to this page [j]" accesskey="j">What links here</a></li><li id="t-recentchangeslinked"><a href="/wiki/Special:RecentChangesLinked/Lexical_analysis" rel="nofollow" title="Recent changes in pages linked from this page [k]" accesskey="k">Related changes</a></li><li id="t-upload"><a href="/wiki/Wikipedia:File_Upload_Wizard" title="Upload files [u]" accesskey="u">Upload file</a></li><li id="t-specialpages"><a href="/wiki/Special:SpecialPages" title="A list of all special pages [q]" accesskey="q">Special pages</a></li><li id="t-permalink"><a href="/w/index.php?title=Lexical_analysis&amp;oldid=807206513" title="Permanent link to this revision of the page">Permanent link</a></li><li id="t-info"><a href="/w/index.php?title=Lexical_analysis&amp;action=info" title="More information about this page">Page information</a></li><li id="t-wikibase"><a href="https://www.wikidata.org/wiki/Special:EntityPage/Q835922" title="Link to connected data repository item [g]" accesskey="g">Wikidata item</a></li><li id="t-cite"><a href="/w/index.php?title=Special:CiteThisPage&amp;page=Lexical_analysis&amp;id=807206513" title="Information on how to cite this page">Cite this page</a></li>					</ul>/n							</div>/n		</div>/n			<div class="portal" role="navigation" id='p-coll-print_export' aria-labelledby='p-coll-print_export-label'>/n			<h3 id='p-coll-print_export-label'>Print/export</h3>/n/n			<div class="body">/n									<ul>/n						<li id="coll-create_a_book"><a href="/w/index.php?title=Special:Book&amp;bookcmd=book_creator&amp;referer=Lexical+analysis">Create a book</a></li><li id="coll-download-as-rdf2latex"><a href="/w/index.php?title=Special:ElectronPdf&amp;page=Lexical+analysis&amp;action=show-download-screen">Download as PDF</a></li><li id="t-print"><a href="/w/index.php?title=Lexical_analysis&amp;printable=yes" title="Printable version of this page [p]" accesskey="p">Printable version</a></li>					</ul>/n							</div>/n		</div>/n			<div class="portal" role="navigation" id='p-lang' aria-labelledby='p-lang-label'>/n			<h3 id='p-lang-label'>Languages</h3>/n/n			<div class="body">/n									<ul>/n						<li class="interlanguage-link interwiki-az"><a href="https://az.wikipedia.org/wiki/Leksem" title="Leksem – Azerbaijani" lang="az" hreflang="az" class="interlanguage-link-target">Azərbaycanca</a></li><li class="interlanguage-link interwiki-ca"><a href="https://ca.wikipedia.org/wiki/An%C3%A0lisi_l%C3%A8xica" title="Anàlisi lèxica – Catalan" lang="ca" hreflang="ca" class="interlanguage-link-target">Català</a></li><li class="interlanguage-link interwiki-cs"><a href="https://cs.wikipedia.org/wiki/Lexik%C3%A1ln%C3%AD_anal%C3%BDza" title="Lexikální analýza – Czech" lang="cs" hreflang="cs" class="interlanguage-link-target">Čeština</a></li><li class="interlanguage-link interwiki-da"><a href="https://da.wikipedia.org/wiki/Leksikalsk_analyse" title="Leksikalsk analyse – Danish" lang="da" hreflang="da" class="interlanguage-link-target">Dansk</a></li><li class="interlanguage-link interwiki-de"><a href="https://de.wikipedia.org/wiki/Tokenizer" title="Tokenizer – German" lang="de" hreflang="de" class="interlanguage-link-target">Deutsch</a></li><li class="interlanguage-link interwiki-el"><a href="https://el.wikipedia.org/wiki/%CE%9B%CE%B5%CE%BA%CF%84%CE%B9%CE%BA%CE%AE_%CE%B1%CE%BD%CE%AC%CE%BB%CF%85%CF%83%CE%B7" title="Λεκτική ανάλυση – Greek" lang="el" hreflang="el" class="interlanguage-link-target">Ελληνικά</a></li><li class="interlanguage-link interwiki-es"><a href="https://es.wikipedia.org/wiki/Analizador_l%C3%A9xico" title="Analizador léxico – Spanish" lang="es" hreflang="es" class="interlanguage-link-target">Español</a></li><li class="interlanguage-link interwiki-fa"><a href="https://fa.wikipedia.org/wiki/%D8%AA%D8%AD%D9%84%DB%8C%D9%84_%D9%88%D8%A7%DA%98%DA%AF%D8%A7%D9%86%DB%8C" title="تحلیل واژگانی – Persian" lang="fa" hreflang="fa" class="interlanguage-link-target">فارسی</a></li><li class="interlanguage-link interwiki-fr"><a href="https://fr.wikipedia.org/wiki/Analyse_lexicale" title="Analyse lexicale – French" lang="fr" hreflang="fr" class="interlanguage-link-target">Français</a></li><li class="interlanguage-link interwiki-ko"><a href="https://ko.wikipedia.org/wiki/%EB%82%B1%EB%A7%90_%EB%B6%84%EC%84%9D" title="낱말 분석 – Korean" lang="ko" hreflang="ko" class="interlanguage-link-target">한국어</a></li><li class="interlanguage-link interwiki-hy"><a href="https://hy.wikipedia.org/wiki/%D4%BC%D5%A5%D6%84%D5%BD%D5%AB%D5%AF%D5%A1%D5%AF%D5%A1%D5%B6_%D5%BE%D5%A5%D6%80%D5%AC%D5%B8%D6%82%D5%AE%D5%B8%D6%82%D5%A9%D5%B5%D5%B8%D6%82%D5%B6" title="Լեքսիկական վերլուծություն – Armenian" lang="hy" hreflang="hy" class="interlanguage-link-target">Հայերեն</a></li><li class="interlanguage-link interwiki-hr"><a href="https://hr.wikipedia.org/wiki/Leksi%C4%8Dka_analiza" title="Leksička analiza – Croatian" lang="hr" hreflang="hr" class="interlanguage-link-target">Hrvatski</a></li><li class="interlanguage-link interwiki-id"><a href="https://id.wikipedia.org/wiki/Analisis_leksikal" title="Analisis leksikal – Indonesian" lang="id" hreflang="id" class="interlanguage-link-target">Bahasa Indonesia</a></li><li class="interlanguage-link interwiki-it"><a href="https://it.wikipedia.org/wiki/Analisi_lessicale" title="Analisi lessicale – Italian" lang="it" hreflang="it" class="interlanguage-link-target">Italiano</a></li><li class="interlanguage-link interwiki-he"><a href="https://he.wikipedia.org/wiki/%D7%A0%D7%99%D7%AA%D7%95%D7%97_%D7%9E%D7%99%D7%9C%D7%95%D7%9C%D7%99" title="ניתוח מילולי – Hebrew" lang="he" hreflang="he" class="interlanguage-link-target">עברית</a></li><li class="interlanguage-link interwiki-mk"><a href="https://mk.wikipedia.org/wiki/%D0%9B%D0%B5%D0%BA%D1%81%D0%B8%D1%87%D0%BA%D0%B8_%D0%B0%D0%BD%D0%B0%D0%BB%D0%B8%D0%B7%D0%B0%D1%82%D0%BE%D1%80" title="Лексички анализатор – Macedonian" lang="mk" hreflang="mk" class="interlanguage-link-target">Македонски</a></li><li class="interlanguage-link interwiki-nl"><a href="https://nl.wikipedia.org/wiki/Lexicale_analyse" title="Lexicale analyse – Dutch" lang="nl" hreflang="nl" class="interlanguage-link-target">Nederlands</a></li><li class="interlanguage-link interwiki-ja"><a href="https://ja.wikipedia.org/wiki/%E5%AD%97%E5%8F%A5%E8%A7%A3%E6%9E%90" title="字句解析 – Japanese" lang="ja" hreflang="ja" class="interlanguage-link-target">日本語</a></li><li class="interlanguage-link interwiki-no"><a href="https://no.wikipedia.org/wiki/Leksikalsk_analyse" title="Leksikalsk analyse – Norwegian" lang="no" hreflang="no" class="interlanguage-link-target">Norsk</a></li><li class="interlanguage-link interwiki-pl"><a href="https://pl.wikipedia.org/wiki/Analiza_leksykalna" title="Analiza leksykalna – Polish" lang="pl" hreflang="pl" class="interlanguage-link-target">Polski</a></li><li class="interlanguage-link interwiki-pt"><a href="https://pt.wikipedia.org/wiki/An%C3%A1lise_l%C3%A9xica" title="Análise léxica – Portuguese" lang="pt" hreflang="pt" class="interlanguage-link-target">Português</a></li><li class="interlanguage-link interwiki-ru"><a href="https://ru.wikipedia.org/wiki/%D0%9B%D0%B5%D0%BA%D1%81%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D0%B9_%D0%B0%D0%BD%D0%B0%D0%BB%D0%B8%D0%B7" title="Лексический анализ – Russian" lang="ru" hreflang="ru" class="interlanguage-link-target">Русский</a></li><li class="interlanguage-link interwiki-sv"><a href="https://sv.wikipedia.org/wiki/Lexikalanalys" title="Lexikalanalys – Swedish" lang="sv" hreflang="sv" class="interlanguage-link-target">Svenska</a></li><li class="interlanguage-link interwiki-ta"><a href="https://ta.wikipedia.org/wiki/%E0%AE%8E%E0%AE%B4%E0%AF%81%E0%AE%A4%E0%AF%8D%E0%AE%A4%E0%AF%81_%E0%AE%AA%E0%AE%BE%E0%AE%95%E0%AF%81%E0%AE%AA%E0%AE%9F%E0%AF%81%E0%AE%A4%E0%AF%8D%E0%AE%A4%E0%AE%BF" title="எழுத்து பாகுபடுத்தி – Tamil" lang="ta" hreflang="ta" class="interlanguage-link-target">தமிழ்</a></li><li class="interlanguage-link interwiki-uk"><a href="https://uk.wikipedia.org/wiki/%D0%9B%D0%B5%D0%BA%D1%81%D0%B8%D1%87%D0%BD%D0%B8%D0%B9_%D0%B0%D0%BD%D0%B0%D0%BB%D1%96%D0%B7" title="Лексичний аналіз – Ukrainian" lang="uk" hreflang="uk" class="interlanguage-link-target">Українська</a></li><li class="interlanguage-link interwiki-vi"><a href="https://vi.wikipedia.org/wiki/Ph%C3%A2n_t%C3%ADch_t%E1%BB%AB_v%E1%BB%B1ng" title="Phân tích từ vựng – Vietnamese" lang="vi" hreflang="vi" class="interlanguage-link-target">Tiếng Việt</a></li><li class="interlanguage-link interwiki-zh"><a href="https://zh.wikipedia.org/wiki/%E8%AF%8D%E6%B3%95%E5%88%86%E6%9E%90" title="词法分析 – Chinese" lang="zh" hreflang="zh" class="interlanguage-link-target">中文</a></li>					</ul>/n				<div class="after-portlet after-portlet-lang"><span class="wb-langlinks-edit wb-langlinks-link"><a href="https://www.wikidata.org/wiki/Special:EntityPage/Q835922#sitelinks-wikipedia" title="Edit interlanguage links" class="wbc-editpage">Edit links</a></span></div>			</div>/n		</div>/n				</div>/n		</div>/n		<div id="footer" role="contentinfo">/n							<ul id="footer-info">/n											<li id="footer-info-lastmod"> This page was last edited on 26 October 2017, at 15:50.</li>/n											<li id="footer-info-copyright">Text is available under the <a rel="license" href="//en.wikipedia.org/wiki/Wikipedia:Text_of_Creative_Commons_Attribution-ShareAlike_3.0_Unported_License">Creative Commons Attribution-ShareAlike License</a><a rel="license" href="//creativecommons.org/licenses/by-sa/3.0/" style="display:none;"></a>;/nadditional terms may apply.  By using this site, you agree to the <a href="//wikimediafoundation.org/wiki/Terms_of_Use">Terms of Use</a> and <a href="//wikimediafoundation.org/wiki/Privacy_policy">Privacy Policy</a>. Wikipedia® is a registered trademark of the <a href="//www.wikimediafoundation.org/">Wikimedia Foundation, Inc.</a>, a non-profit organization.</li>/n									</ul>/n							<ul id="footer-places">/n											<li id="footer-places-privacy"><a href="https://wikimediafoundation.org/wiki/Privacy_policy" class="extiw" title="wmf:Privacy policy">Privacy policy</a></li>/n											<li id="footer-places-about"><a href="/wiki/Wikipedia:About" title="Wikipedia:About">About Wikipedia</a></li>/n											<li id="footer-places-disclaimer"><a href="/wiki/Wikipedia:General_disclaimer" title="Wikipedia:General disclaimer">Disclaimers</a></li>/n											<li id="footer-places-contact"><a href="//en.wikipedia.org/wiki/Wikipedia:Contact_us">Contact Wikipedia</a></li>/n											<li id="footer-places-developers"><a href="https://www.mediawiki.org/wiki/Special:MyLanguage/How_to_contribute">Developers</a></li>/n											<li id="footer-places-cookiestatement"><a href="https://wikimediafoundation.org/wiki/Cookie_statement">Cookie statement</a></li>/n											<li id="footer-places-mobileview"><a href="//en.m.wikipedia.org/w/index.php?title=Lexical_analysis&amp;mobileaction=toggle_view_mobile" class="noprint stopMobileRedirectToggle">Mobile view</a></li>/n									</ul>/n										<ul id="footer-icons" class="noprint">/n											<li id="footer-copyrightico">/n							<a href="https://wikimediafoundation.org/"><img src="/static/images/wikimedia-button.png" srcset="/static/images/wikimedia-button-1.5x.png 1.5x, /static/images/wikimedia-button-2x.png 2x" width="88" height="31" alt="Wikimedia Foundation"/></a>						</li>/n											<li id="footer-poweredbyico">/n							<a href="//www.mediawiki.org/"><img src="/static/images/poweredby_mediawiki_88x31.png" alt="Powered by MediaWiki" srcset="/static/images/poweredby_mediawiki_132x47.png 1.5x, /static/images/poweredby_mediawiki_176x62.png 2x" width="88" height="31"/></a>						</li>/n									</ul>/n						<div style="clear:both"></div>/n		</div>/n		<script>(window.RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgPageParseReport":{"limitreport":{"cputime":"0.216","walltime":"0.285","ppvisitednodes":{"value":1697,"limit":1000000},"ppgeneratednodes":{"value":0,"limit":1500000},"postexpandincludesize":{"value":18113,"limit":2097152},"templateargumentsize":{"value":2531,"limit":2097152},"expansiondepth":{"value":15,"limit":40},"expensivefunctioncount":{"value":3,"limit":500},"entityaccesscount":{"value":0,"limit":400},"timingprofile":["100.00%  249.120      1 -total"," 30.81%   76.760      2 Template:Reflist"," 22.02%   54.853      3 Template:Cite_web"," 21.84%   54.417      2 Template:Fix"," 16.89%   42.079      1 Template:Dubious"," 11.66%   29.041      1 Template:Redirect"," 11.39%   28.377      3 Template:Category_handler"," 11.23%   27.987      3 Template:ISBN","  8.96%   22.318      2 Template:Delink","  7.38%   18.396      1 Template:Citation_needed"]},"scribunto":{"limitreport-timeusage":{"value":"0.098","limit":"10.000"},"limitreport-memusage":{"value":3198027,"limit":52428800}},"cachereport":{"origin":"mw1285","timestamp":"20171026155002","ttl":1900800,"transientcontent":false}}});});</script><script>(window.RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgBackendResponseTime":87,"wgHostname":"mw1275"});});</script>/n	</body>/n</html>/n